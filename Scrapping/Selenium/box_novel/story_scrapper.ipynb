{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a56c00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromedriver_autoinstaller\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime, timedelta\n",
    "from pysqlite import Sqlite\n",
    "import uuid\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5fa0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127dcc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def remove_invalid_chars(string):\n",
    "    return \"\".join([c for c in string if c.isalpha() ])\n",
    "\n",
    "def create_folder(story_name, root=\"stories\"):\n",
    "    folder = os.path.join(root, story_name )\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    return folder\n",
    "\n",
    "def save_chapter_text(folder, chap_id, chap_text):\n",
    "    filename = os.path.join(folder, f\"chapter_{chap_id}.txt\")\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(chap_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40fd728",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxNovelTracker:\n",
    "    __url__    = \"https://boxnovel.com/\"\n",
    "    __source__ = \"BoxNovel\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self._db_engine     = Sqlite.init(\"story_data.db\")\n",
    "        self.load_stories   ()\n",
    "        self.__filesfolder__= f\"{self.__source__}_files\"\n",
    "        \n",
    "        if not os.path.exists (self.__filesfolder__):\n",
    "            os.makedirs(self.__filesfolder__)\n",
    "    \n",
    "    @property\n",
    "    def datetime(self):\n",
    "        return datetime.now().strftime(\"%Y-%d-%m %H:%M:%S.%f\")\n",
    "    \n",
    "    @property\n",
    "    def stories(self):\n",
    "        self.load_stories()\n",
    "        return self._stories\n",
    "    \n",
    "    def _get_file_path(self, storyid):\n",
    "        uid    = str(uuid.uuid4()).replace(\"-\", \"\")\n",
    "        folder = f\"{self.__filesfolder__}/{storyid}\" \n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            \n",
    "        return f\"{folder}/{storyid}{uid}.txt\"\n",
    "    def process_releaseddate(self, released_date):\n",
    "        if 'day ago' in released_date:\n",
    "             dt = datetime.now() - timedelta(days=1)\n",
    "        elif 'days ago' in released_date:\n",
    "            dt = datetime.now() - timedelta( days=int( released_date.split(\" \")[0] ) )\n",
    "        elif 'hours ago' in released_date:\n",
    "            dt = datetime.now() - timedelta( hours= int(released_date.split(\" \")[0]) )\n",
    "        elif 'hour ago' in released_date:\n",
    "            dt = datetime.now() - timedelta( hours=1)\n",
    "        else:\n",
    "            dt = datetime.strptime(released_date, \"%B %d, %Y\")\n",
    "        \n",
    "        return dt.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    \n",
    "    def load_stories(self):\n",
    "        data = self._db_engine.read(\"story\", \"*\", where=f\"source='{self.__source__}'\")\n",
    "        self._stories = { s['name']:s for s in data} if len(data) > 0 else {}\n",
    "        \n",
    "    def exists(self, name):\n",
    "        \"\"\" return true if story already exists otherwise false \"\"\"\n",
    "        return True if name in self._stories.keys() else False\n",
    "    \n",
    "    def latest_update(self, storyid):\n",
    "        \"\"\" return latest update of given story if update exists otherwise None \"\"\"\n",
    "        return self._db_engine.read('storydata', '*', where=f'storyid={storyid}', limit=1, orderby=\"entrydate DESC\", single=True)\n",
    "    \n",
    "    def get_existing_chapters(self, storyid):\n",
    "        \"\"\" return all of the scrapped chapters \"\"\"\n",
    "        return self._db_engine.read('storydata', '*', where=f'storyid={storyid}', orderby=\"entrydate DESC\")\n",
    "    \n",
    "    def save(self, name, url):\n",
    "        \"\"\" save new story into db and reload stories \"\"\"\n",
    "        story = {\"name\":name, \"url\":url, \"source\":self.__source__, \"sourceurl\":self.__url__, \"entrydate\":self.datetime}\n",
    "        if self._db_engine.save(\"story\", story):\n",
    "            self.load_stories(); return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def save_storydata(self, storyid, chapname, releaseddate, content):\n",
    "        filepath = self._get_file_path(storyid)\n",
    "        with open(filepath, 'w') as file:\n",
    "            file.write(content)\n",
    "        \n",
    "        released_date = self.process_releaseddate(releaseddate)\n",
    "        record        = { 'storyid':storyid, 'chaptername':chapname, 'releaseddate':released_date, \n",
    "                          'datafile':filepath, 'entrydate':self.datetime}\n",
    "        return self._db_engine.save('storydata', record)\n",
    "    \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0ee838e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\H P\\\\Envs\\\\scrapperenv\\\\lib\\\\site-packages\\\\chromedriver_autoinstaller\\\\105\\\\chromedriver.exe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = webdriver.ChromeOptions()\n",
    "opt.add_argument(\"--start-maximized\")\n",
    "\n",
    "chromedriver_autoinstaller.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "978420c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f520b219",
   "metadata": {},
   "source": [
    "## Fetch New Stories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecc0dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = BoxNovelTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d2c21aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exiting\n"
     ]
    }
   ],
   "source": [
    "page_no = 1\n",
    "MAX_TRY = 3\n",
    "tracker = BoxNovelTracker()\n",
    "\n",
    "while True:\n",
    "    url = f\"https://boxnovel.com/page/{page_no}/\"\n",
    "    \n",
    "    count = 0\n",
    "    while count < MAX_TRY:\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            break\n",
    "        except:\n",
    "            print(f\"[{count}/{MAX_TRY}] failed to fetch url ({url}) - retrying \", end=\"\\r\")\n",
    "            count += 1\n",
    "            time.sleep(2)\n",
    "    \n",
    "    if count < MAX_TRY:\n",
    "        if driver.title == \"Page not found â€“ BoxNovel\":\n",
    "            print('exiting')\n",
    "            break\n",
    "            \n",
    "        stories = driver.find_elements(By.CLASS_NAME, \"item-summary\")\n",
    "        if len(stories) > 0:\n",
    "            for s in stories:\n",
    "                atag = s.find_element(By.TAG_NAME, \"a\")\n",
    "                name = atag.text\n",
    "                url  = atag.get_attribute(\"href\")\n",
    "                if not tracker.exists(name):\n",
    "                    tracker.save(name, url)\n",
    "        \n",
    "        else:\n",
    "            print('no stroy found at ', url)\n",
    "    \n",
    "    else: \n",
    "        print('skipping ', url)\n",
    "    page_no += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27bc7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c7007f9",
   "metadata": {},
   "source": [
    "## Fetch Story Chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3aed2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = BoxNovelTracker()\n",
    "driver1 = webdriver.Chrome(options=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26740357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chapters found for 1 - fetching its latest chapters\n",
      "fetching 5 new chapters for  1\n",
      "chapters found for 2 - fetching its latest chapters\n",
      "fetching 11 new chapters for  2\n",
      "chapters found for 3 - fetching its latest chapters\n",
      "fetching 8 new chapters for  3\n",
      "chapters found for 4 - fetching its latest chapters\n",
      "fetching 8 new chapters for  4\n",
      "chapters found for 5 - fetching its latest chapters\n",
      "fetching 14 new chapters for  5\n",
      "chapters found for 6 - fetching its latest chapters\n",
      "fetching 9 new chapters for  6\n",
      "chapters found for 7 - fetching its latest chapters\n",
      "fetching 19 new chapters for  7\n",
      "no record found for 8 - fethcing all of its chapters\n",
      "fetching 251 for  8\n",
      "chapters found for 9 - fetching its latest chapters\n",
      "fetching 100 new chapters for  9\n",
      "no record found for 10 - fethcing all of its chapters\n",
      "fetching 71 for  10\n",
      "[70/71]\r"
     ]
    }
   ],
   "source": [
    "# latest one\n",
    "stories = tracker.stories\n",
    "c = 0\n",
    "for key, story in stories.items():\n",
    "    count = 0\n",
    "    while count < 3:\n",
    "        try   : driver.get(story[\"url\"]); break\n",
    "        except: count +=1 \n",
    "    time.sleep(3)\n",
    "    if count < 3:\n",
    "        try: driver.find_element(By.CLASS_NAME, 'chapter-readmore').click(); time.sleep(1)\n",
    "        except:pass\n",
    "        chapters = driver.find_elements(By.CLASS_NAME, 'wp-manga-chapter    ')\n",
    "        \n",
    "        latest_record = tracker.latest_update(story['id'])\n",
    "        if latest_record is None:\n",
    "            print(f'no record found for {story[\"id\"]} - fethcing all of its chapters')\n",
    "\n",
    "            print(f'fetching {len(chapters)} for ', story[\"id\"])\n",
    "            for i, chapter in enumerate(chapters):\n",
    "                try:\n",
    "                    atag     = chapter.find_element(By.TAG_NAME, 'a')\n",
    "                    chaplink = atag.get_attribute(\"href\")\n",
    "                    chapname = atag.text\n",
    "                    rdate    = chapter.find_element(By.XPATH, \"//span[@class='chapter-release-date']\").text\n",
    "                    driver1.get(chaplink)\n",
    "                    time.sleep(1)\n",
    "                    content      = driver1.find_element(By.CLASS_NAME, \"entry-content\")\n",
    "                    chapter_text = content.find_element(By.CLASS_NAME, \"text-left\")\n",
    "\n",
    "                    ps           = chapter_text.find_elements(By.TAG_NAME, \"p\")\n",
    "                    ps_text      = \"\\n\".join( [p.text for p in ps] )\n",
    "\n",
    "                    tracker.save_storydata(story[\"id\"], chapname, rdate, ps_text)\n",
    "\n",
    "                except:print('failed to fetch chapter ', i)\n",
    "                print(f'[{i}/{len(chapters)}]', end='\\r')\n",
    "        else:\n",
    "            print(f'chapters found for {story[\"id\"]} - fetching its latest chapters')\n",
    "            saved_chapters  = [c['chaptername'] for c in tracker.get_existing_chapters( story[\"id\"] ) ]\n",
    "            new_chapters    = [ (chapter.find_element(By.TAG_NAME, 'a').get_attribute(\"href\"),\n",
    "                                 chapter.find_element(By.TAG_NAME, 'a').text,\n",
    "                                 chapter.find_element(By.XPATH, \"//span[@class='chapter-release-date']\").text)\n",
    "                              for chapter in chapters]\n",
    "            chapters_to_save= [c for c in new_chapters if c[1] not in saved_chapters]\n",
    "            print(f'fetching {len(chapters_to_save)} new chapters for ', story[\"id\"])\n",
    "            for i, chap in enumerate(chapters_to_save):\n",
    "                try:\n",
    "                    driver1.get(chap[0])\n",
    "                    time.sleep(1)\n",
    "                    content      = driver1.find_element(By.CLASS_NAME, \"entry-content\")\n",
    "                    chapter_text = content.find_element(By.CLASS_NAME, \"text-left\")\n",
    "\n",
    "                    ps           = chapter_text.find_elements(By.TAG_NAME, \"p\")\n",
    "                    ps_text      = \"\\n\".join( [p.text for p in ps] )\n",
    "\n",
    "                    tracker.save_storydata(story[\"id\"], chap[1], chap[2], ps_text)\n",
    "                except:pass\n",
    "                print(f'[{i}/{len(chapters_to_save)}]', end='\\r')\n",
    "    else:\n",
    "        print('failed to load ', story['url'], ' - skipping it')\n",
    "    \n",
    "    \n",
    "    c+=1\n",
    "    if c == 10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b7f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no record found for 1 - fethcing its all chapters\n",
      "fetching 894 for  1\n",
      "failed to fetch chapter  36\n",
      "failed to fetch chapter  56\n",
      "failed to fetch chapter  138\n",
      "failed to fetch chapter  144\n",
      "failed to fetch chapter  271\n",
      "no record found for 2 - fethcing its all chapters\n",
      "fetching 2066 for  2\n",
      "failed to fetch chapter  8\n",
      "failed to fetch chapter  9\n",
      "failed to fetch chapter  37\n",
      "failed to fetch chapter  44\n",
      "failed to fetch chapter  86\n",
      "failed to fetch chapter  466\n",
      "failed to fetch chapter  733\n",
      "failed to fetch chapter  763\n",
      "[838/2066]\r"
     ]
    }
   ],
   "source": [
    "# old one\n",
    "stories = tracker.stories\n",
    "c = 0\n",
    "for key, story in stories.items():\n",
    "    latest_record = tracker.latest_update(story['id'])\n",
    "    if latest_record is None:\n",
    "        print(f'no record found for {story[\"id\"]} - fethcing its all chapters')\n",
    "        \n",
    "        count = 0\n",
    "        while count < 3:\n",
    "            try   : driver.get(story[\"url\"]); break\n",
    "            except: count +=1 \n",
    "        time.sleep(3)\n",
    "        if count < 3:\n",
    "            try: driver.find_element(By.CLASS_NAME, 'chapter-readmore').click(); time.sleep(1)\n",
    "            except:pass\n",
    "            chapters = driver.find_elements(By.CLASS_NAME, 'wp-manga-chapter    ')\n",
    "            print(f'fetching {len(chapters)} for ', story[\"id\"])\n",
    "            for i, chapter in enumerate(chapters):\n",
    "                try:\n",
    "                    atag     = chapter.find_element(By.TAG_NAME, 'a')\n",
    "                    chaplink = atag.get_attribute(\"href\")\n",
    "                    chapname = atag.text\n",
    "                    rdate    = chapter.find_element(By.XPATH, \"//span[@class='chapter-release-date']\").text\n",
    "                    driver1.get(chaplink)\n",
    "                    time.sleep(1)\n",
    "                    content      = driver1.find_element(By.CLASS_NAME, \"entry-content\")\n",
    "                    chapter_text = content.find_element(By.CLASS_NAME, \"text-left\")\n",
    "\n",
    "                    ps           = chapter_text.find_elements(By.TAG_NAME, \"p\")\n",
    "                    ps_text      = \"\\n\".join( [p.text for p in ps] )\n",
    "                    \n",
    "                    tracker.save_storydata(story[\"id\"], chapname, rdate, ps_text)\n",
    "                    \n",
    "                except:print('failed to fetch chapter ', i)\n",
    "                print(f'[{i}/{len(chapters)}]', end='\\r')\n",
    "        else:\n",
    "            print('failed to load ', story['url'], ' - skipping it')\n",
    "    \n",
    "    else:\n",
    "        print(f'chapters found for {story[\"id\"]} - fetching its latest chapters')\n",
    "        chapters     = tracker.get_existing_chapters(story[\"id\"])\n",
    "        new_chapters = \n",
    "    \n",
    "    \n",
    "    c+=1\n",
    "    if c == 10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6564434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc420989",
   "metadata": {},
   "outputs": [],
   "source": [
    "url       = \"https://boxnovel.com/novel/top-tier-providence-secretly-cultivate-for-a-thousand-years/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c1cdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_more = driver.find_element(By.CLASS_NAME, 'chapter-readmore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48947c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_more.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "971a6c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "894"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapters = driver.find_elements(By.CLASS_NAME, 'wp-manga-chapter    ')\n",
    "len(chapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26a58d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 894 - Divine Might Great Heaven Palm, Azure Heaven Mystic  ->  6 hours ago\n"
     ]
    }
   ],
   "source": [
    "chapter  = chapters[0]\n",
    "atag     = chapter.find_element(By.TAG_NAME, 'a')\n",
    "chaplink = atag.get_attribute(\"href\")\n",
    "chapname = atag.text\n",
    "rdate    = chapter.find_element(By.XPATH, \"//span[@class='chapter-release-date']\").text\n",
    "\n",
    "print(chapname, ' -> ', rdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "663bc267",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver1.get(chaplink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bff392e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of content ->  8869\n"
     ]
    }
   ],
   "source": [
    "content      = driver1.find_element(By.CLASS_NAME, \"entry-content\")\n",
    "chapter_text = content.find_element(By.CLASS_NAME, \"text-left\")\n",
    "\n",
    "ps           = chapter_text.find_elements(By.TAG_NAME, \"p\")\n",
    "ps_text      = \"\\n\".join( [p.text for p in ps] )\n",
    "print(\"length of content -> \", len(ps_text) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "124175d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker.save_storydata(1, chapname, rdate, ps_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c63dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0d5e8c5",
   "metadata": {},
   "source": [
    "### Extract Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e646868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\H P\\Envs\\scrapperenv\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: find_elements_by_class_name is deprecated. Please use find_elements(by=By.CLASS_NAME, value=name) instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "stories     = driver.find_elements_by_class_name(\"item-summary\")\n",
    "print       (len(stories) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "661f11d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\H P\\Envs\\scrapperenv\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:341: UserWarning: find_element_by_tag_name is deprecated. Please use find_element(by=By.TAG_NAME, value=name) instead\n",
      "  warnings.warn(\"find_element_by_tag_name is deprecated. Please use find_element(by=By.TAG_NAME, value=name) instead\")\n",
      "C:\\Users\\H P\\Envs\\scrapperenv\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:446: UserWarning: find_element_by_class_name is deprecated. Please use find_element(by=By.CLASS_NAME, value=name) instead\n",
      "  warnings.warn(\"find_element_by_class_name is deprecated. Please use find_element(by=By.CLASS_NAME, value=name) instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story-links ->  20\n"
     ]
    }
   ],
   "source": [
    "story_links = [(s.find_element_by_tag_name(\"a\").get_attribute(\"href\"), s.find_element_by_tag_name(\"a\").text,\n",
    "                s.find_element_by_class_name(\"chapter\").text,\n",
    "                s.find_element_by_class_name(\"chapter-item\").find_element_by_class_name(\"post-on\").text) for s in stories] \n",
    "print       (\"story-links -> \", len(story_links) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819894eb",
   "metadata": {},
   "source": [
    "## Chapter Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da10688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story in story_links:\n",
    "    link, name, lastchap, lastupdate = story\n",
    "    # extract story info\n",
    "    driver.get       (link)\n",
    "    time.sleep       (3)\n",
    "    key              = remove_invalid_chars( name )\n",
    "    \n",
    "    # move to first page\n",
    "    read_first       = driver.find_element_by_id(\"btn-read-last\")\n",
    "    read_first.click ()\n",
    "    time.sleep       (3)\n",
    "    \n",
    "    # create folder to store data\n",
    "    folder_name = create_folder(story_name=key)\n",
    "    chap_id     = 1\n",
    "    while True:\n",
    "        retry = 0\n",
    "        while retry < 5:\n",
    "            try:\n",
    "                content      = driver.find_element_by_class_name(\"entry-content\")\n",
    "                chapter_text = content.find_element_by_class_name(\"text-left\")\n",
    "\n",
    "                try:\n",
    "                    chapter_name = chapter_text.find_element_by_tag_name(\"h1\").text\n",
    "                except:\n",
    "                    chapter_name = chapter_text.find_element_by_tag_name(\"h3\").text\n",
    "                print(\"chapter name -> \", chapter_name)\n",
    "\n",
    "                ps           = chapter_text.find_elements_by_tag_name(\"p\")\n",
    "                ps_text      = \"\\n\".join( [p.text for p in ps] )\n",
    "                ps_text      = chapter_name + \"\\n\" + ps_text\n",
    "                print(\"length of content -> \", len(ps_text) )\n",
    "\n",
    "                save_chapter_text(folder_name, chap_id, ps_text)\n",
    "                chap_id      += 1\n",
    "                break\n",
    "            except:\n",
    "                print(\"failed to fetch content- trying again...\")\n",
    "                time.sleep(5)\n",
    "                retry += 1\n",
    "\n",
    "        retry = 0\n",
    "        while retry < 3:\n",
    "            try:\n",
    "                footer       = driver.find_element_by_id(\"manga-reading-nav-foot\")\n",
    "\n",
    "                next_page    = footer.find_element_by_xpath(\"//div[@class='nav-links']//div[@class='nav-next ']//a[@class='btn next_page']\")\n",
    "                next_page.click()\n",
    "                time.sleep(2)\n",
    "                retry = 0\n",
    "                break\n",
    "            except:\n",
    "                retry += 1\n",
    "                time.sleep(3)\n",
    "\n",
    "        if retry == 3:\n",
    "            break\n",
    "    \n",
    "    db.save(\"story\", {\"key\":key, \"name\":name, \"chapters\":chap_id, \"lastchapter\":lastchap, \"lastupdated\":lastupdate, \"storylink\":link, \"websource\":url})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e764d527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5093142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad045e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfdf36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2202af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
